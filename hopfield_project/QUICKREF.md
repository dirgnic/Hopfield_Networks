# Quick Reference Card
## Hopfield Networks Project

### ğŸš€ Quick Start
```bash
cd hopfield_project
chmod +x setup.sh
./setup.sh
```

### ğŸ“ File Structure
```
hopfield_project/
â”œâ”€â”€ src/               # Core implementation
â”‚   â”œâ”€â”€ hopfield.py   # Main network class
â”‚   â”œâ”€â”€ patterns.py   # Pattern generation
â”‚   â””â”€â”€ visualization.py  # Plotting tools
â”œâ”€â”€ experiments/       # All experiments
â”œâ”€â”€ figures/          # Generated plots
â”œâ”€â”€ latex_presentation/  # Slides & report
â””â”€â”€ notebooks/        # Jupyter notebook
```

### ğŸ§ª Run Experiments
```bash
# Quick demo
python demo.py

# Full experiments
cd experiments
python basic_retrieval.py      # Memory recall
python capacity_test.py        # Storage limits
python noise_robustness.py     # Noise tolerance
python spurious_attractors.py  # False memories
```

### ğŸ“Š Key Results
- **Capacity**: ~14 patterns (0.138 Ã— 100 neurons)
- **Noise tolerance**: Up to 25-30% corruption
- **Convergence**: 5-15 iterations typical
- **Spurious attractors**: Emerge above capacity

### ğŸ§  Brain Analogies Cheat Sheet
| Component | Math | Brain Analogy |
|-----------|------|---------------|
| Neuron state | s_i âˆˆ {-1,+1} | Firing (+1) or silent (-1) |
| Pattern | Î¾ = (sâ‚,...,sâ‚™) | Brain state snapshot |
| Weights | w_ij | Synaptic connections |
| Learning | w_ij = Î£ Î¾áµ¢Â·Î¾â±¼ | "Fire together, wire together" |
| Energy | E = -Â½Î£w_ijÂ·s_iÂ·s_j | Stability landscape |
| Update | s_i = sign(Î£w_ijÂ·s_j) | Neuron listens to inputs |
| Retrieval | Noisy â†’ Original | "Hear notes â†’ recall song" |

### ğŸ“ LaTeX Commands
```bash
cd latex_presentation

# Compile project description
pdflatex project_description.tex
pdflatex project_description.tex

# Compile presentation
pdflatex presentation.tex
pdflatex presentation.tex
```

### ğŸ¯ Three-Act Structure
**Act I**: Protein folding â†’ Energy landscapes â†’ Brain dynamics

**Act II**: Implementation with analogies
1. Neurons & patterns â†’ Brain states
2. Hebbian learning â†’ Synaptic plasticity  
3. Dynamics â†’ Energy minimization
4. Retrieval â†’ Associative memory

**Act III**: Experiments â†’ Capacity â†’ Spurious attractors â†’ Transformers

### ğŸ’¡ Key Equations
**Hebbian learning:**
```
w_ij = (1/N) Î£_Î¼ Î¾_i^Î¼ Â· Î¾_j^Î¼  (iâ‰ j)
```

**Update rule:**
```
s_i^(t+1) = sign(Î£_j w_ij Â· s_j^(t))
```

**Energy:**
```
E(s) = -Â½ Î£_ij w_ij Â· s_i Â· s_j
```

### ğŸ”§ Troubleshooting
```bash
# Can't run experiments?
cd experiments
python basic_retrieval.py

# Import errors?
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# No plots showing?
export MPLBACKEND=TkAgg
```

### ğŸ“š References
1. Hopfield (1982) - PNAS original paper
2. YouTube: "A Brain-Inspired Algorithm For Memory"
3. Ramsauer et al. (2020) - "Hopfield Networks is All You Need"

### âœ… Checklist for Presentation
- [ ] Run all experiments
- [ ] Generate all figures
- [ ] Copy figures to latex_presentation/
- [ ] Update figure paths in presentation.tex
- [ ] Compile LaTeX documents
- [ ] Practice three-act narrative
- [ ] Prepare brain analogy examples
- [ ] Test demo on presentation machine

---
**2024 Nobel Prize in Physics** ğŸ†
John Hopfield & Geoffrey Hinton
