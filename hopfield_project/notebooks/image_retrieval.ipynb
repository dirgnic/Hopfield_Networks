{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f73bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from src.hopfield import HopfieldNetwork\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec980b4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Create Simple Images\n",
    "\n",
    "We'll create simple geometric patterns that can be stored as binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd26e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_images(size=20):\n",
    "    \"\"\"\n",
    "    Create simple geometric patterns as binary images.\n",
    "    \n",
    "    Returns:\n",
    "        images: list of (size, size) arrays with values in {-1, +1}\n",
    "        names: list of image names\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    names = []\n",
    "    \n",
    "    # 1. Vertical bars\n",
    "    vertical = -np.ones((size, size))\n",
    "    vertical[:, size//4:size//4+2] = 1\n",
    "    vertical[:, 3*size//4:3*size//4+2] = 1\n",
    "    images.append(vertical)\n",
    "    names.append('Vertical Bars')\n",
    "    \n",
    "    # 2. Horizontal bars\n",
    "    horizontal = -np.ones((size, size))\n",
    "    horizontal[size//4:size//4+2, :] = 1\n",
    "    horizontal[3*size//4:3*size//4+2, :] = 1\n",
    "    images.append(horizontal)\n",
    "    names.append('Horizontal Bars')\n",
    "    \n",
    "    # 3. Cross\n",
    "    cross = -np.ones((size, size))\n",
    "    cross[size//2-1:size//2+1, :] = 1\n",
    "    cross[:, size//2-1:size//2+1] = 1\n",
    "    images.append(cross)\n",
    "    names.append('Cross')\n",
    "    \n",
    "    # 4. Diagonal\n",
    "    diagonal = -np.ones((size, size))\n",
    "    for i in range(size):\n",
    "        if i > 0:\n",
    "            diagonal[i, i] = 1\n",
    "            diagonal[i, i-1] = 1\n",
    "            diagonal[i-1, i] = 1\n",
    "    images.append(diagonal)\n",
    "    names.append('Diagonal')\n",
    "    \n",
    "    # 5. Frame\n",
    "    frame = -np.ones((size, size))\n",
    "    frame[0:2, :] = 1\n",
    "    frame[-2:, :] = 1\n",
    "    frame[:, 0:2] = 1\n",
    "    frame[:, -2:] = 1\n",
    "    images.append(frame)\n",
    "    names.append('Frame')\n",
    "    \n",
    "    # 6. Checkerboard\n",
    "    checker = -np.ones((size, size))\n",
    "    checker[::2, ::2] = 1\n",
    "    checker[1::2, 1::2] = 1\n",
    "    images.append(checker)\n",
    "    names.append('Checkerboard')\n",
    "    \n",
    "    return images, names\n",
    "\n",
    "# Create images\n",
    "image_size = 20\n",
    "images, image_names = create_simple_images(image_size)\n",
    "\n",
    "print(f\"Created {len(images)} images\")\n",
    "print(f\"Image size: {image_size}x{image_size} = {image_size*image_size} pixels\")\n",
    "print(f\"Each pixel: +1 (white) or -1 (black)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153736d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (img, name) in enumerate(zip(images, image_names)):\n",
    "    axes[idx].imshow(img, cmap='binary', interpolation='nearest')\n",
    "    axes[idx].set_title(name, fontsize=14, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Image Gallery: Patterns to Store in Memory', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85709b45",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Train the Network\n",
    "\n",
    "**Brain Analogy:** The network \"memorizes\" these images by strengthening connections between co-active pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images to 1D vectors\n",
    "patterns = np.array([img.flatten() for img in images])\n",
    "\n",
    "print(f\"Pattern matrix shape: {patterns.shape}\")\n",
    "print(f\"Number of patterns: {patterns.shape[0]}\")\n",
    "print(f\"Neurons per pattern: {patterns.shape[1]}\")\n",
    "\n",
    "# Create and train network\n",
    "n_neurons = image_size * image_size\n",
    "hopfield = HopfieldNetwork(n_neurons=n_neurons)\n",
    "hopfield.train(patterns)\n",
    "\n",
    "print(f\"\\nNetwork trained!\")\n",
    "print(f\"Weight matrix: {hopfield.weights.shape}\")\n",
    "print(f\"Total connections: {n_neurons * (n_neurons - 1) // 2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723fe69",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Image Completion (Inpainting)\n",
    "\n",
    "**Demo:** Show only part of an image, let the network complete it.\n",
    "\n",
    "Like seeing half a face and recognizing who it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partial_image(pattern, missing_fraction=0.5, mode='random'):\n",
    "    \"\"\"\n",
    "    Create a partial image by hiding some pixels.\n",
    "    \n",
    "    Parameters:\n",
    "        pattern: Original pattern\n",
    "        missing_fraction: Fraction of pixels to hide (0-1)\n",
    "        mode: 'random', 'top', 'bottom', 'left', 'right', 'center'\n",
    "    \"\"\"\n",
    "    partial = pattern.copy()\n",
    "    n = len(pattern)\n",
    "    size = int(np.sqrt(n))\n",
    "    \n",
    "    if mode == 'random':\n",
    "        # Random pixels\n",
    "        n_missing = int(n * missing_fraction)\n",
    "        missing_indices = np.random.choice(n, n_missing, replace=False)\n",
    "        partial[missing_indices] = np.random.choice([-1, 1], size=n_missing)\n",
    "    \n",
    "    elif mode == 'top':\n",
    "        # Hide top half\n",
    "        partial_2d = partial.reshape(size, size)\n",
    "        n_rows = int(size * missing_fraction)\n",
    "        partial_2d[:n_rows, :] = np.random.choice([-1, 1], size=(n_rows, size))\n",
    "        partial = partial_2d.flatten()\n",
    "    \n",
    "    elif mode == 'bottom':\n",
    "        # Hide bottom half\n",
    "        partial_2d = partial.reshape(size, size)\n",
    "        n_rows = int(size * missing_fraction)\n",
    "        partial_2d[-n_rows:, :] = np.random.choice([-1, 1], size=(n_rows, size))\n",
    "        partial = partial_2d.flatten()\n",
    "    \n",
    "    elif mode == 'left':\n",
    "        # Hide left half\n",
    "        partial_2d = partial.reshape(size, size)\n",
    "        n_cols = int(size * missing_fraction)\n",
    "        partial_2d[:, :n_cols] = np.random.choice([-1, 1], size=(size, n_cols))\n",
    "        partial = partial_2d.flatten()\n",
    "    \n",
    "    elif mode == 'right':\n",
    "        # Hide right half\n",
    "        partial_2d = partial.reshape(size, size)\n",
    "        n_cols = int(size * missing_fraction)\n",
    "        partial_2d[:, -n_cols:] = np.random.choice([-1, 1], size=(size, n_cols))\n",
    "        partial = partial_2d.flatten()\n",
    "    \n",
    "    elif mode == 'center':\n",
    "        # Hide center region\n",
    "        partial_2d = partial.reshape(size, size)\n",
    "        margin = int(size * (1 - missing_fraction) / 2)\n",
    "        partial_2d[margin:-margin, margin:-margin] = np.random.choice(\n",
    "            [-1, 1], size=(size - 2*margin, size - 2*margin)\n",
    "        )\n",
    "        partial = partial_2d.flatten()\n",
    "    \n",
    "    return partial\n",
    "\n",
    "# Test image completion\n",
    "test_idx = 2  # Cross pattern\n",
    "original = patterns[test_idx]\n",
    "modes = ['top', 'bottom', 'left', 'right', 'center', 'random']\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(16, 8))\n",
    "\n",
    "for col, mode in enumerate(modes):\n",
    "    # Create partial image\n",
    "    partial = create_partial_image(original, missing_fraction=0.5, mode=mode)\n",
    "    \n",
    "    # Retrieve\n",
    "    retrieved, info = hopfield.retrieve(partial, max_iter=50)\n",
    "    \n",
    "    # Show original\n",
    "    axes[0, col].imshow(original.reshape(image_size, image_size), \n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    axes[0, col].set_title(f'{mode.capitalize()}\\nOriginal', fontsize=10)\n",
    "    axes[0, col].axis('off')\n",
    "    \n",
    "    # Show partial\n",
    "    axes[1, col].imshow(partial.reshape(image_size, image_size), \n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    axes[1, col].set_title(f'50% Hidden', fontsize=10)\n",
    "    axes[1, col].axis('off')\n",
    "    \n",
    "    # Show retrieved\n",
    "    axes[2, col].imshow(retrieved.reshape(image_size, image_size), \n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    success = np.array_equal(retrieved, original)\n",
    "    color = 'green' if success else 'red'\n",
    "    axes[2, col].set_title(f'Retrieved\\n({info[\"iterations\"]} iter)', \n",
    "                          fontsize=10, color=color, fontweight='bold')\n",
    "    axes[2, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Image Completion: {image_names[test_idx]}', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Green titles = Perfect retrieval\")\n",
    "print(\"Red titles = Failed retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5824ef0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Image Denoising\n",
    "\n",
    "**Demo:** Add noise (random pixel flips) and let the network clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda58d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test denoising on all images\n",
    "noise_levels = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "fig, axes = plt.subplots(len(images), len(noise_levels) + 1, figsize=(14, 12))\n",
    "\n",
    "for row, (pattern, name) in enumerate(zip(patterns, image_names)):\n",
    "    # Show original\n",
    "    axes[row, 0].imshow(pattern.reshape(image_size, image_size),\n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    axes[row, 0].set_ylabel(name, fontsize=12, fontweight='bold', rotation=0,\n",
    "                           ha='right', va='center')\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    # Test different noise levels\n",
    "    for col, noise in enumerate(noise_levels):\n",
    "        # Add noise\n",
    "        noisy = hopfield.add_noise(pattern, noise_level=noise)\n",
    "        \n",
    "        # Retrieve\n",
    "        retrieved, info = hopfield.retrieve(noisy, max_iter=50)\n",
    "        \n",
    "        # Show result\n",
    "        axes[row, col+1].imshow(retrieved.reshape(image_size, image_size),\n",
    "                                cmap='binary', interpolation='nearest')\n",
    "        \n",
    "        # Color code by success\n",
    "        success = np.array_equal(retrieved, pattern)\n",
    "        color = 'green' if success else 'red'\n",
    "        \n",
    "        if row == 0:\n",
    "            axes[row, col+1].set_title(f'{int(noise*100)}% Noise',\n",
    "                                       fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Add border\n",
    "        for spine in axes[row, col+1].spines.values():\n",
    "            spine.set_edgecolor(color)\n",
    "            spine.set_linewidth(3 if success else 2)\n",
    "        \n",
    "        axes[row, col+1].axis('off')\n",
    "\n",
    "plt.suptitle('Image Denoising: Noise Robustness Test', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Green border = Perfect recovery\")\n",
    "print(\"Red border = Failed recovery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a8490",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Quantitative Analysis\n",
    "\n",
    "Let's measure retrieval accuracy vs noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58415494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic noise robustness test\n",
    "noise_range = np.linspace(0, 0.5, 11)\n",
    "results = {name: [] for name in image_names}\n",
    "\n",
    "print(\"Testing noise robustness...\")\n",
    "print(\"Noise%  \" + \"  \".join([f\"{name[:8]:>8}\" for name in image_names]))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for noise in noise_range:\n",
    "    accuracies = []\n",
    "    \n",
    "    for pattern, name in zip(patterns, image_names):\n",
    "        # Run 20 trials\n",
    "        trials = 20\n",
    "        successes = 0\n",
    "        \n",
    "        for _ in range(trials):\n",
    "            noisy = hopfield.add_noise(pattern, noise_level=noise)\n",
    "            retrieved, _ = hopfield.retrieve(noisy, max_iter=50)\n",
    "            if np.array_equal(retrieved, pattern):\n",
    "                successes += 1\n",
    "        \n",
    "        accuracy = successes / trials\n",
    "        results[name].append(accuracy)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Print row\n",
    "    print(f\"{int(noise*100):3d}%    \" + \n",
    "          \"  \".join([f\"{acc:>8.0%}\" for acc in accuracies]))\n",
    "\n",
    "print()\n",
    "print(\"Observation: Some patterns are more robust to noise than others!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63feabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot noise robustness curves\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for name in image_names:\n",
    "    plt.plot(noise_range * 100, results[name], 'o-', \n",
    "             linewidth=2, markersize=6, label=name)\n",
    "\n",
    "plt.xlabel('Noise Level (%)', fontsize=13)\n",
    "plt.ylabel('Retrieval Success Rate', fontsize=13)\n",
    "plt.title('Image Retrieval: Noise Robustness', fontsize=15, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"- Simpler patterns (vertical, horizontal) are more robust\")\n",
    "print(\"- Complex patterns (checkerboard) fail earlier\")\n",
    "print(\"- Why? Simple patterns have stronger, clearer attractor basins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037dc3a3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Interactive Retrieval Demo\n",
    "\n",
    "Watch the network converge step-by-step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step retrieval visualization\n",
    "test_idx = 0  # Vertical bars\n",
    "original = patterns[test_idx]\n",
    "noisy = hopfield.add_noise(original, noise_level=0.3)\n",
    "\n",
    "# Retrieve with trajectory tracking\n",
    "retrieved, info = hopfield.retrieve(noisy, max_iter=20, record_trajectory=True)\n",
    "\n",
    "# Get trajectory\n",
    "trajectory = info['state_trajectory']\n",
    "energies = info['energy_trajectory']\n",
    "\n",
    "# Show key steps\n",
    "steps_to_show = [0, 1, 2, 3, 5, len(trajectory)-1]\n",
    "steps_to_show = [s for s in steps_to_show if s < len(trajectory)]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(steps_to_show), figsize=(16, 6))\n",
    "\n",
    "for idx, step in enumerate(steps_to_show):\n",
    "    state = trajectory[step]\n",
    "    energy = energies[step]\n",
    "    hamming = hopfield.hamming_distance(state, original)\n",
    "    \n",
    "    # Show image\n",
    "    axes[0, idx].imshow(state.reshape(image_size, image_size),\n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    axes[0, idx].set_title(f'Step {step}\\nE={energy:.1f}', fontsize=11)\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # Show error map\n",
    "    error_map = (state != original).reshape(image_size, image_size)\n",
    "    axes[1, idx].imshow(error_map, cmap='RdYlGn_r', interpolation='nearest')\n",
    "    axes[1, idx].set_title(f'Errors: {hamming}', fontsize=11)\n",
    "    axes[1, idx].axis('off')\n",
    "\n",
    "plt.suptitle(f'Step-by-Step Retrieval: {image_names[test_idx]}',\n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConverged in {info['iterations']} iterations\")\n",
    "print(f\"Energy decreased: {energies[0]:.2f} â†’ {energies[-1]:.2f}\")\n",
    "print(f\"Errors corrected: {hopfield.hamming_distance(noisy, original)} â†’ 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot energy convergence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Energy trajectory\n",
    "ax1.plot(energies, 'o-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Energy', fontsize=12)\n",
    "ax1.set_title('Energy Minimization (Rolling Downhill)', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Hamming distance trajectory\n",
    "hamming_trajectory = [hopfield.hamming_distance(state, original) \n",
    "                      for state in trajectory]\n",
    "ax2.plot(hamming_trajectory, 'o-', linewidth=2, markersize=8, color='red')\n",
    "ax2.set_xlabel('Iteration', fontsize=12)\n",
    "ax2.set_ylabel('Hamming Distance (Errors)', fontsize=12)\n",
    "ax2.set_title('Error Correction Progress', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBrain Analogy:\")\n",
    "print(\"The network 'rolls downhill' in energy space, correcting errors along the way!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5935b9e",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Real-World Application Demo\n",
    "\n",
    "Let's simulate a realistic use case: **Photo Restoration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc030457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate old photo restoration\n",
    "test_idx = 4  # Frame pattern\n",
    "original = patterns[test_idx]\n",
    "\n",
    "# Simulate different types of damage\n",
    "damage_types = [\n",
    "    ('Random Scratches', 'random', 0.25),\n",
    "    ('Top Torn Off', 'top', 0.4),\n",
    "    ('Water Damage (Center)', 'center', 0.3),\n",
    "    ('Right Side Faded', 'right', 0.35),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "for col, (damage_name, mode, fraction) in enumerate(damage_types):\n",
    "    # Create damaged version\n",
    "    if 'Scratches' in damage_name:\n",
    "        damaged = hopfield.add_noise(original, noise_level=fraction)\n",
    "    else:\n",
    "        damaged = create_partial_image(original, missing_fraction=fraction, mode=mode)\n",
    "    \n",
    "    # Restore\n",
    "    restored, info = hopfield.retrieve(damaged, max_iter=50)\n",
    "    \n",
    "    # Show damaged\n",
    "    axes[0, col].imshow(damaged.reshape(image_size, image_size),\n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    axes[0, col].set_title(f'{damage_name}\\n(Damaged)', fontsize=10, color='red')\n",
    "    axes[0, col].axis('off')\n",
    "    \n",
    "    # Show restored\n",
    "    axes[1, col].imshow(restored.reshape(image_size, image_size),\n",
    "                        cmap='binary', interpolation='nearest')\n",
    "    success = np.array_equal(restored, original)\n",
    "    color = 'green' if success else 'orange'\n",
    "    status = 'Perfect!' if success else 'Partial'\n",
    "    axes[1, col].set_title(f'Restored\\n({status})', fontsize=10, color=color, fontweight='bold')\n",
    "    axes[1, col].axis('off')\n",
    "\n",
    "plt.suptitle('Photo Restoration with Hopfield Network', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReal-World Applications:\")\n",
    "print(\"- Old photo restoration\")\n",
    "print(\"- Document cleaning (remove stains, tears)\")\n",
    "print(\"- Image inpainting (fill missing regions)\")\n",
    "print(\"- OCR preprocessing (clean noisy scans)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a31881",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What We Demonstrated:\n",
    "\n",
    "1. **Image Storage**: Stored 6 different geometric patterns as memories\n",
    "\n",
    "2. **Image Completion**: Network reconstructs full images from partial input\n",
    "   - Works with 50% missing pixels\n",
    "   - Various occlusion patterns (top, bottom, left, right, center)\n",
    "\n",
    "3. **Image Denoising**: Network cleans corrupted images\n",
    "   - Robust up to 20-30% noise\n",
    "   - Different patterns have different noise tolerance\n",
    "\n",
    "4. **Convergence Dynamics**: Watched energy decrease step-by-step\n",
    "   - Energy minimization (rolling downhill)\n",
    "   - Error correction (Hamming distance reduction)\n",
    "\n",
    "5. **Real-World Simulation**: Photo restoration with various damage types\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Content-Addressable Memory**: Give partial input â†’ get complete output\n",
    "- **Associative Recall**: Network finds closest stored pattern\n",
    "- **Pattern Complexity Matters**: Simple patterns more robust than complex ones\n",
    "- **Energy Landscape**: Memories as valleys, retrieval as rolling downhill\n",
    "\n",
    "### Brain Connection:\n",
    "\n",
    "Just like human memory:\n",
    "- See part of a face â†’ recognize the whole person\n",
    "- Hear a few notes â†’ recall the whole song\n",
    "- Read messy handwriting â†’ understand the text\n",
    "\n",
    "**The Hopfield network is a computational model of associative memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7934d0fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Your Turn: Experiments!\n",
    "\n",
    "Try these:\n",
    "\n",
    "1. **Create your own patterns** - Design custom 20Ã—20 images\n",
    "2. **Test capacity** - How many images can you store before it fails?\n",
    "3. **Mix images** - What happens with 50% image A + 50% image B?\n",
    "4. **Change size** - Try 10Ã—10 or 30Ã—30 images\n",
    "5. **Add multiple damage types** - Combine noise + partial occlusion\n",
    "\n",
    "Have fun! ðŸ§ âœ¨"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
